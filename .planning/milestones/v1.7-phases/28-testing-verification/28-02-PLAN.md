---
phase: 28-testing-verification
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - server/src/provider/OpenAiProvider.test.ts
  - server/src/provider/CopilotProvider.test.ts
  - server/src/orchestrator/WorkflowOrchestrator.integration.test.ts
autonomous: true
requirements: [TEST-01, TEST-02, TEST-04]

must_haves:
  truths:
    - "OpenAiProvider unit tests cover message history management across turns"
    - "OpenAiProvider unit tests cover structured output parsing with json_schema"
    - "OpenAiProvider unit tests cover card action conversion to text"
    - "CopilotProvider unit tests cover all three LlmProvider methods"
    - "Orchestrator integration test drives a multi-turn workflow to completion using mocked LlmProvider"
    - "npm test is green with all new and existing tests passing"
  artifacts:
    - path: "server/src/provider/OpenAiProvider.test.ts"
      provides: "OpenAiProvider unit tests with mocked OpenAI SDK"
      min_lines: 100
    - path: "server/src/provider/CopilotProvider.test.ts"
      provides: "CopilotProvider unit tests with mocked CopilotStudioClient"
      min_lines: 40
    - path: "server/src/orchestrator/WorkflowOrchestrator.integration.test.ts"
      provides: "Multi-turn orchestrator integration test with mocked LlmProvider"
      min_lines: 100
  key_links:
    - from: "server/src/orchestrator/WorkflowOrchestrator.integration.test.ts"
      to: "server/src/orchestrator/WorkflowOrchestrator.ts"
      via: "import WorkflowOrchestrator, mock LlmProvider"
      pattern: "import.*WorkflowOrchestrator"
---

<objective>
Audit and extend existing test files for OpenAiProvider (TEST-01), CopilotProvider (TEST-02), and the orchestrator integration test (TEST-04). Fill any coverage gaps and verify `npm test` passes.

Purpose: TEST-01, TEST-02, and TEST-04 may be partially covered by tests created during Phases 24-26. This plan audits existing coverage against v1.7 requirements and adds any missing test cases. The integration test must specifically demonstrate driving a multi-turn workflow to COMPLETION (action: 'complete') using a mocked LlmProvider.

Output: Updated test files with full coverage; `npm test` green across all workspaces.
</objective>

<execution_context>
@/Users/zycroft/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zycroft/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/REQUIREMENTS.md
@server/src/provider/OpenAiProvider.test.ts
@server/src/provider/CopilotProvider.test.ts
@server/src/orchestrator/WorkflowOrchestrator.integration.test.ts
@server/src/provider/OpenAiProvider.ts
@server/src/provider/CopilotProvider.ts
@server/src/orchestrator/WorkflowOrchestrator.ts
@server/src/provider/LlmProvider.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Audit and extend OpenAiProvider + CopilotProvider tests (TEST-01, TEST-02)</name>
  <files>server/src/provider/OpenAiProvider.test.ts, server/src/provider/CopilotProvider.test.ts</files>
  <action>
**Audit existing OpenAiProvider.test.ts (12 tests):**
The file already covers:
- Constructor with default/custom model
- startSession: returns NormalizedMessage with greeting + extractedPayload
- sendMessage: system prompt + user message, structured data, history accumulation (OAPI-04), json_schema response_format (OAPI-02), default model (OAPI-06)
- sendCardAction: conversion to text (OAPI-05)
- extractedPayload schema compatibility

Check against TEST-01 requirements: "message history management, structured output parsing, and card action conversion." All three areas appear covered. Verify completeness:
- Message history management: ✓ (test "includes prior turn in history on second call")
- Structured output parsing: ✓ (test "returns NormalizedMessage with extractedPayload")
- Card action conversion: ✓ (test "converts action to text description")

If any edge cases are missing, add them:
1. If no test for error handling when OpenAI returns malformed JSON — add one that mocks a response with unparseable content and verifies the provider handles it gracefully (throws or returns error message).
2. If no test for empty conversation history (sendMessage without prior startSession) — add if the provider supports it, or verify it throws.

**Audit existing CopilotProvider.test.ts (4 tests):**
The file covers:
- startSession: collects streaming activities and normalizes (1 test + 1 empty test)
- sendMessage: builds activity and normalizes (1 test)
- sendCardAction: builds card action activity (1 test)

TEST-02 requirement: "Unit tests for CopilotProvider with mocked CopilotStudioClient." All three LlmProvider methods are tested. The coverage is adequate since CopilotProvider is a thin wrapper — it delegates to CopilotStudioClient (mocked) and normalizeActivities (mocked).

If any obvious gaps exist (e.g., error propagation when streaming fails), add a test case. Otherwise confirm TEST-02 is satisfied by existing tests.

**Minimal additions expected.** Do NOT add tests just to pad counts — only add tests that cover genuine untested behavior paths.
  </action>
  <verify>cd server && npx vitest run src/provider/OpenAiProvider.test.ts src/provider/CopilotProvider.test.ts</verify>
  <done>OpenAiProvider.test.ts covers message history, structured output parsing, and card action conversion. CopilotProvider.test.ts covers all three LlmProvider methods with mocked client. TEST-01 and TEST-02 satisfied.</done>
</task>

<task type="auto">
  <name>Task 2: Verify and extend orchestrator integration test (TEST-04)</name>
  <files>server/src/orchestrator/WorkflowOrchestrator.integration.test.ts</files>
  <action>
**Audit existing WorkflowOrchestrator.integration.test.ts (5 tests):**
The file currently covers:
- 3-turn data accumulation with context preamble verification
- Turn count incrementing across 3 turns
- Passthrough mode (no structured data)
- Parse error handling (invalid action)
- All 3 parsedTurn kinds exercised (passthrough, structured, parse_error)

TEST-04 requirement: "Integration test: multi-turn conversation through orchestrator with mocked LlmProvider."

**Key check:** Does the existing test drive a workflow to COMPLETION? The 3-turn accumulation test ends with `action: 'complete'` on turn 3 — this IS a completion. The test verifies `turn3Result.workflowState.collectedData` has all accumulated data. This satisfies TEST-04.

**However**, verify the test explicitly checks the workflow reached the 'complete' step. If the test only checks collectedData but doesn't verify `workflowState.step === 'complete'` or `workflowState.status`, add an assertion:
```typescript
expect(turn3Result.workflowState.step).toBe('complete');
```

Also verify the integration test already uses a mocked `LlmProvider` — it does (see `mockLlmProvider` with `startSession`, `sendMessage`, `sendCardAction` mock functions). This satisfies the "mocked LlmProvider" requirement.

**Add if missing:**
1. Assert that the workflow step transitions from 'gather_info' through intermediate steps to 'complete'
2. Assert that the final workflowState has `status: 'active'` or the appropriate terminal status
3. Verify that the test description explicitly references TEST-04 for traceability

Run `npm test` across ALL workspaces after changes to confirm no regressions (TEST-05 success criterion #1: `npm test` is green).
  </action>
  <verify>
    <automated>cd /Users/zycroft/Documents/PA/aaae && npm test</automated>
    <manual>Verify all test suites pass: client (4 suites), server (15+ suites)</manual>
  </verify>
  <done>Integration test drives multi-turn workflow to completion with mocked LlmProvider (TEST-04 satisfied). npm test passes across all workspaces with no regressions.</done>
</task>

</tasks>

<verification>
1. `cd server && npx vitest run src/provider/OpenAiProvider.test.ts` — OpenAiProvider tests pass
2. `cd server && npx vitest run src/provider/CopilotProvider.test.ts` — CopilotProvider tests pass
3. `cd server && npx vitest run src/orchestrator/WorkflowOrchestrator.integration.test.ts` — integration test passes
4. `npm test` — all tests green across all workspaces (client + server)
</verification>

<success_criteria>
- OpenAiProvider tests cover message history, structured output, card actions (TEST-01)
- CopilotProvider tests cover all LlmProvider methods with mocked client (TEST-02)
- Integration test drives multi-turn workflow to completion with mocked LlmProvider (TEST-04)
- `npm test` is green with all new and existing tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/28-testing-verification/28-02-SUMMARY.md`
</output>
