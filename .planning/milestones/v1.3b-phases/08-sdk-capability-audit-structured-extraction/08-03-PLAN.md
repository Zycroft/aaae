---
phase: 08-sdk-capability-audit-structured-extraction
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - spike/latency-baseline.ts
  - spike/LATENCY-RESULTS.md
autonomous: false
requirements:
  - PERF-01
  - PERF-02
  - PERF-03

must_haves:
  truths:
    - "A developer can read documented latency medians for startConversation, sendMessage, and full round-trip from a file in spike/"
    - "Each metric has 5+ samples with the median reported"
    - "The spike script connects to the real Copilot Studio agent (no mocks)"
  artifacts:
    - path: "spike/latency-baseline.ts"
      provides: "Executable Node/tsx script measuring startConversation, sendMessage, round-trip latencies"
      contains: "startConversation"
    - path: "spike/LATENCY-RESULTS.md"
      provides: "Documented latency measurements with sample data and medians for all three metrics"
      contains: "median"
  key_links:
    - from: "spike/latency-baseline.ts"
      to: "server/src/copilot.ts"
      via: "imports CopilotStudioClient, ConnectionSettings, and config values directly"
      pattern: "CopilotStudioClient|ConnectionSettings"
    - from: "spike/LATENCY-RESULTS.md"
      to: "spike/latency-baseline.ts"
      via: "Results populated from running the script against real Copilot Studio"
      pattern: "median|ms"
---

<objective>
Create a latency measurement spike script and a populated results document measuring startConversation, sendMessage, and full round-trip against the real Copilot Studio agent.

Purpose: Phase 10 evaluation (SDK-EVALUATION.md) requires real latency numbers to make the GO/CONDITIONAL GO recommendation. This spike produces the raw data.

Output: spike/latency-baseline.ts (runnable script), spike/LATENCY-RESULTS.md (filled with real measurements after human runs the script with real credentials).
</objective>

<execution_context>
@/Users/zycroft/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zycroft/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@server/src/copilot.ts
@server/src/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create latency measurement spike script</name>
  <files>spike/latency-baseline.ts</files>
  <action>
Create the `spike/` directory and `spike/latency-baseline.ts` as a standalone executable script (NOT part of the server workspace — it imports from server modules directly using relative paths).

The script must:

1. **Import SDK and config** — import `CopilotStudioClient`, `ConnectionSettings` from `@microsoft/agents-copilotstudio-client`, load env vars from `server/.env` using dotenv (path: `../server/.env` relative to spike/), and read `COPILOT_ENVIRONMENT_ID`, `COPILOT_AGENT_SCHEMA_NAME`, `COPILOT_STUB_TOKEN` from `process.env`.

2. **Measure startConversation** — run `client.startConversationStreaming(true)` consuming the full async generator, measure wall-clock time from call start to generator completion. Run 5 times, collect all samples in milliseconds.

3. **Measure sendMessage** — after one startConversation (to establish SDK internal state), send a fixed message ("hello") via `client.sendActivityStreaming(activity)` consuming the full async generator, measure from call start to generator completion. Run 5 times, reusing the same client (each call is sequential — no parallel SDK calls).

4. **Measure full round-trip** — wrap each sendMessage measurement to also include request setup time: from the moment the route handler would receive the request (build Activity object) to the moment `normalizeActivities()` finishes. Import `normalizeActivities` from `../server/src/normalizer/activityNormalizer.js`. Run 5 times.

5. **Compute and print medians** — sort each sample array, take the middle value. Print a formatted table:

```
=== Copilot Studio SDK Latency Baseline ===

startConversation (5 samples):
  Samples: [XXXms, XXXms, ...]
  Median:  XXXms

sendMessage to first activity (5 samples):
  Samples: [XXXms, ...]
  Median:  XXXms

Full round-trip (5 samples):
  Samples: [XXXms, ...]
  Median:  XXXms

Copy these numbers into spike/LATENCY-RESULTS.md
```

6. **Error handling** — wrap each measurement run in try/catch. If the Copilot Studio connection fails (stub credentials), catch and print a clear message: `"[ERROR] Copilot Studio connection failed. Ensure server/.env has real COPILOT_* credentials."` then exit 1.

**Script execution** (run from repo root):
```bash
npx tsx spike/latency-baseline.ts
```

The script is a standalone TypeScript file (not registered in any workspace package.json). It uses tsx for execution since tsx is already installed at root dev deps. Confirm tsx is available: `ls node_modules/.bin/tsx`.

NOTE: Do NOT mock any Copilot responses — per v1.3b constraints, all latency measurements must use the real Copilot Studio agent.
  </action>
  <verify>
Confirm the script parses without TypeScript errors (import check only, not execution with real creds):

```bash
npx tsx --no-cache spike/latency-baseline.ts 2>&1 | head -5
```

If credentials are stub/missing, the script should print the error message and exit 1 — that is the expected behavior without real credentials. The output should NOT be a TypeScript compilation error.

Verify the spike/ directory exists:
```bash
ls spike/latency-baseline.ts
```
  </verify>
  <done>
- spike/latency-baseline.ts exists and is valid TypeScript (tsx parses it without type errors)
- Script measures startConversation, sendMessage, full round-trip with 5 samples each
- Medians are computed and printed
- Script gracefully handles credential failures with clear error message
- Script can be run with `npx tsx spike/latency-baseline.ts`
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Checkpoint: Run latency script with real credentials and provide measurements</name>
  <files>spike/LATENCY-RESULTS.md</files>
  <action>
    Human runs `npx tsx spike/latency-baseline.ts` with real Copilot Studio credentials and provides the output. Claude then creates spike/LATENCY-RESULTS.md with the real measurement data.
  </action>
  <verify>spike/LATENCY-RESULTS.md exists and contains real latency medians for all three metrics.</verify>
  <done>spike/LATENCY-RESULTS.md has documented medians for startConversation, sendMessage, and full round-trip (PERF-01, PERF-02, PERF-03).</done>
  <what-built>
    Task 1 created spike/latency-baseline.ts — a script that measures Copilot Studio SDK latency for startConversation, sendMessage, and full round-trip using 5 samples each.

    Claude cannot run this script with real results because real Copilot Studio credentials are required (server/.env must have real COPILOT_ENVIRONMENT_ID, COPILOT_AGENT_SCHEMA_NAME, COPILOT_STUB_TOKEN or equivalent).

    Claude will create spike/LATENCY-RESULTS.md after you provide the measurements.
  </what-built>
  <how-to-verify>
    1. Ensure `server/.env` has real Copilot Studio credentials (COPILOT_ENVIRONMENT_ID, COPILOT_AGENT_SCHEMA_NAME, COPILOT_STUB_TOKEN)
    2. Run the script from the repo root:
       ```
       npx tsx spike/latency-baseline.ts
       ```
    3. Wait for all 15 measurements to complete (may take 30–120 seconds depending on agent latency)
    4. Note the printed medians for all three metrics
    5. If the script fails with a connection error, check that credentials in server/.env are valid and the Copilot Studio agent is reachable

    Expected: Three sections of output with 5 samples and a median for each metric.

    Please provide the output so spike/LATENCY-RESULTS.md can be populated with real numbers.
  </how-to-verify>
  <resume-signal>
    Paste the script output (the three measurement sections with samples and medians), or type "skip" if credentials are not available and you want a placeholder document with [TBD] values.
  </resume-signal>
</task>

</tasks>

<verification>
After checkpoint approval:
1. spike/latency-baseline.ts exists and runs without TypeScript errors
2. spike/LATENCY-RESULTS.md exists and contains real (or placeholder) latency measurements
3. LATENCY-RESULTS.md has sections for startConversation, sendMessage, and full round-trip (PERF-01, PERF-02, PERF-03)
4. `npm test` from repo root still passes (spike files are not part of test suite)
</verification>

<success_criteria>
- spike/latency-baseline.ts is a runnable measurement script using the real Copilot Studio SDK
- spike/LATENCY-RESULTS.md documents latency medians for all three metrics (PERF-01, PERF-02, PERF-03) with 5+ samples each
- No existing tests broken
</success_criteria>

<output>
After completion (including checkpoint), create `.planning/phases/08-sdk-capability-audit-structured-extraction/08-03-SUMMARY.md`

Also create spike/LATENCY-RESULTS.md with the measurements provided at the checkpoint (or placeholder values if skipped). Template:

```markdown
# Copilot Studio SDK Latency Baseline

**Date:** {date}
**Agent:** {COPILOT_AGENT_SCHEMA_NAME value}
**Environment:** {COPILOT_ENVIRONMENT_ID value}

## startConversation() — PERF-01

| Sample | Latency (ms) |
|--------|-------------|
| 1 | {value} |
| 2 | {value} |
| 3 | {value} |
| 4 | {value} |
| 5 | {value} |
| **Median** | **{median}** |

## sendMessage() to First Activity — PERF-02

| Sample | Latency (ms) |
|--------|-------------|
| 1 | {value} |
| ... | ... |
| **Median** | **{median}** |

## Full Round-Trip — PERF-03

(Request received → normalizeActivities() complete)

| Sample | Latency (ms) |
|--------|-------------|
| 1 | {value} |
| ... | ... |
| **Median** | **{median}** |

## Notes

{Any observations about variance, timeouts, agent behavior}
```
</output>
