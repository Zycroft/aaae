---
phase: 02-text-chat-end-to-end
plan: "03"
type: execute
wave: 3
depends_on:
  - "02-02"
files_modified:
  - client/src/api/chatApi.ts
  - client/src/hooks/useChatApi.ts
autonomous: true
requirements:
  - UI-09

must_haves:
  truths:
    - "useChatApi exposes startConversation(), sendMessage(), transcript state, isLoading flag, and conversationId"
    - "sendMessage() performs an optimistic dispatch before the fetch resolves"
    - "sendMessage() auto-retries on 5xx or network timeout up to 3 times with exponential backoff"
    - "sendMessage() dispatches an error action (not a thrown exception) when all retries are exhausted"
    - "The loading skeleton state is set with a 300ms delay to prevent flicker on fast responses"
    - "useChatApi auto-calls startConversation() on mount when no conversationId exists"
  artifacts:
    - path: "client/src/api/chatApi.ts"
      provides: "Raw fetch wrappers: startConversation, sendMessage"
      exports: ["startConversation", "sendMessage"]
    - path: "client/src/hooks/useChatApi.ts"
      provides: "useReducer-based transcript state + retry logic"
      exports: ["useChatApi", "TranscriptMessage"]
  key_links:
    - from: "client/src/hooks/useChatApi.ts"
      to: "client/src/api/chatApi.ts"
      via: "import startConversation, sendMessage"
      pattern: "startConversation|sendMessage"
    - from: "client/src/api/chatApi.ts"
      to: "POST /api/chat/start, POST /api/chat/send"
      via: "fetch('/api/chat/start'), fetch('/api/chat/send')"
      pattern: "fetch.*api/chat"
    - from: "client/src/hooks/useChatApi.ts"
      to: "@copilot-chat/shared NormalizedMessage"
      via: "TypeScript import for TranscriptMessage type"
      pattern: "NormalizedMessage"
---

<objective>
Create the `useChatApi` hook and underlying `chatApi` fetch layer that power all client-server communication.

Purpose: UI-09 mandates a single hook centralizing all fetch logic with retry. This is the client's data layer — components will consume `useChatApi` without knowing about fetch, retry, or conversation IDs.

Output: `client/src/api/chatApi.ts` with raw fetch wrappers, and `client/src/hooks/useChatApi.ts` with the full `useReducer`-based state machine and retry logic.
</objective>

<execution_context>
@/Users/zycroft/.claude/get-shit-done/workflows/execute-plan.md
@/Users/zycroft/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/phases/02-text-chat-end-to-end/02-RESEARCH.md
@.planning/phases/02-text-chat-end-to-end/02-CONTEXT.md
@shared/src/schemas/api.ts
@shared/src/schemas/message.ts
@client/src/App.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create client/src/api/chatApi.ts — raw fetch wrappers</name>
  <files>client/src/api/chatApi.ts</files>
  <action>
    Create `client/src/api/chatApi.ts`. This module owns raw HTTP communication only — no state, no retry logic (that lives in the hook).

    **Functions to export:**

    ```typescript
    // Starts a new conversation. Returns { conversationId: string }.
    export async function startConversation(signal?: AbortSignal): Promise<{ conversationId: string }>;

    // Sends a message. Returns { conversationId, messages: NormalizedMessage[] }.
    export async function sendMessage(
      conversationId: string,
      text: string,
      signal?: AbortSignal
    ): Promise<{ conversationId: string; messages: NormalizedMessage[] }>;
    ```

    Implementation notes:
    - Use `fetch('/api/chat/start', { method: 'POST', signal })` — the Vite dev proxy at `/api` is already configured in `client/vite.config.ts`
    - Include `Content-Type: application/json` header on POST /send
    - Body for /send: `JSON.stringify({ conversationId, text })`
    - On non-ok response, throw an Error with the status code preserved: `throw Object.assign(new Error(\`HTTP \${res.status}\`), { status: res.status })`
    - Import `NormalizedMessage` type from `@copilot-chat/shared`
    - Do NOT add an Authorization header — the server's `AUTH_REQUIRED=false` will be used in dev; production auth is a v2 concern
    - Do NOT catch errors here — callers handle retry
  </action>
  <verify>
    TypeScript compiles clean:
    ```bash
    cd /Users/zycroft/Documents/PA/aaae/client && npx tsc --noEmit
    ```
    File exists and exports the two functions:
    ```bash
    grep -n "export async function" /Users/zycroft/Documents/PA/aaae/client/src/api/chatApi.ts
    ```
  </verify>
  <done>
    `client/src/api/chatApi.ts` exists, exports `startConversation` and `sendMessage`, compiles clean with TypeScript.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create client/src/hooks/useChatApi.ts — state machine + retry</name>
  <files>client/src/hooks/useChatApi.ts</files>
  <action>
    Create `client/src/hooks/useChatApi.ts`. This hook wraps chatApi.ts with state management, optimistic updates, and retry logic.

    **State shape** (implement with `useReducer`):

    ```typescript
    type MessageStatus = 'sending' | 'sent' | 'error';

    export type TranscriptMessage = NormalizedMessage & {
      status?: MessageStatus;
      errorMessage?: string;
    };

    type State = {
      conversationId: string | null;
      messages: TranscriptMessage[];
      isLoading: boolean;  // true = skeleton should show
      error: string | null;  // global error (e.g., failed to start conversation)
    };
    ```

    **Actions**:
    - `INIT_CONVERSATION`: sets conversationId
    - `ADD_OPTIMISTIC_MESSAGE`: adds user message with status='sending'
    - `START_LOADING`: sets isLoading=true (dispatched after 300ms delay)
    - `SEND_SUCCESS`: sets isLoading=false, appends bot messages with status='sent', updates optimistic message to status='sent'
    - `SEND_ERROR`: sets isLoading=false, updates optimistic message to status='error' with errorMessage
    - `GLOBAL_ERROR`: sets error string (for startConversation failures)

    **Hook signature**:

    ```typescript
    export function useChatApi(): {
      conversationId: string | null;
      messages: TranscriptMessage[];
      isLoading: boolean;
      error: string | null;
      sendMessage: (text: string) => Promise<void>;
    }
    ```

    **sendMessage implementation**:
    1. Generate optimistic message: `{ id: crypto.randomUUID(), role: 'user', kind: 'text', text, status: 'sending' }`
    2. Dispatch ADD_OPTIMISTIC_MESSAGE immediately
    3. Start a 300ms timer → dispatch START_LOADING (per CONTEXT.md: loading indicator delayed ~300ms)
    4. Call `sendMessageWithRetry(conversationId, text)` (see below)
    5. On success: clearTimeout(timer), dispatch SEND_SUCCESS with bot messages, dispatch START_LOADING is cancelled
    6. On final failure: clearTimeout(timer), dispatch SEND_ERROR with errorMessage on the optimistic message

    **fetchWithRetry helper** (inside the module, not exported):
    - Max 3 retries (Claude's discretion per CONTEXT.md)
    - Retry condition: status >= 500 OR network error (Error.name === 'AbortError' → do NOT retry, rethrow)
    - Backoff: 200ms, 400ms, 800ms (2^attempt * 200ms)
    - After 3 failed attempts, throw the last error

    **Lifecycle**:
    - `useEffect` on mount: call `startConversation()`, dispatch INIT_CONVERSATION, dispatch GLOBAL_ERROR on failure
    - Include `AbortController` cleanup in the useEffect return to cancel in-flight requests on unmount

    **Input disabled signal**: The hook exposes `isLoading` — the UI reads this to disable the input (per CONTEXT.md locked decision).

    Notes:
    - Use `crypto.randomUUID()` for optimistic message IDs (available in modern browsers; no uuid package needed in client)
    - Import NormalizedMessage from '@copilot-chat/shared'
    - The optimistic message ID is client-generated and permanent. Bot reply messages come from the server with server-generated IDs.
    - Do NOT add the optimistic message to `history` sent to server — the server generates its own record
  </action>
  <verify>
    TypeScript compiles clean:
    ```bash
    cd /Users/zycroft/Documents/PA/aaae/client && npx tsc --noEmit
    ```
    Hook exports are present:
    ```bash
    grep -n "export function useChatApi\|export type TranscriptMessage" /Users/zycroft/Documents/PA/aaae/client/src/hooks/useChatApi.ts
    ```
    Retry logic is present:
    ```bash
    grep -n "fetchWithRetry\|maxRetries\|backoff\|attempt" /Users/zycroft/Documents/PA/aaae/client/src/hooks/useChatApi.ts
    ```
    300ms delay is present:
    ```bash
    grep -n "300\|SKELETON_DELAY\|setTimeout" /Users/zycroft/Documents/PA/aaae/client/src/hooks/useChatApi.ts
    ```
  </verify>
  <done>
    `client/src/hooks/useChatApi.ts` exists, exports `useChatApi` and `TranscriptMessage`, uses `useReducer` (not useState), implements retry with exponential backoff, dispatches optimistic updates before the fetch, and uses a 300ms delayed skeleton. TypeScript compiles clean.
  </done>
</task>

</tasks>

<verification>
```bash
cd /Users/zycroft/Documents/PA/aaae/client && npx tsc --noEmit
```
Must exit 0 with no errors.
</verification>

<success_criteria>
- [ ] `client/src/api/chatApi.ts` exists with `startConversation` and `sendMessage` exports
- [ ] `client/src/hooks/useChatApi.ts` exists with `useChatApi` and `TranscriptMessage` exports
- [ ] Hook uses `useReducer` for all state transitions (not scattered `useState`)
- [ ] Optimistic user bubble dispatched before any fetch starts
- [ ] Loading state delayed 300ms (setTimeout cleared on fast response)
- [ ] Retry logic: max 3 attempts, 5xx + network errors trigger retry, AbortError does not
- [ ] Exponential backoff: 200ms, 400ms, 800ms delays
- [ ] `useChatApi` auto-calls `startConversation` on mount
- [ ] AbortController cleanup on unmount
- [ ] `cd client && npx tsc --noEmit` exits 0
</success_criteria>

<output>
After completion, create `.planning/phases/02-text-chat-end-to-end/02-03-SUMMARY.md`
</output>
