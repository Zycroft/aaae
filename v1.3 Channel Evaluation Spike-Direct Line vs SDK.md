# v1.3 Milestone Prompt — Channel Evaluation Spike (Direct Line vs Copilot Studio SDK)

## Priority: P1 (Decision gate — affects all downstream architecture)

## Context

This is a React + Express monorepo chat app that currently communicates with Microsoft Copilot Studio via `@microsoft/agents-copilotstudio-client` (the Copilot Studio SDK / Agents SDK). The target architecture diagram (`p1.1 flow architecture.md`) shows **Bot Framework Direct Line** as the communication channel between the Node backend and Copilot Studio.

Before committing to either path for the Workflow Orchestrator (v1.5), we need a time-boxed spike to evaluate both options with working proof-of-concepts.

The system will evolve into a **dynamic, AI-driven workflow orchestrator** where the Node backend:
- Sends research queries with constraints to Copilot
- Parses structured JSON output from Copilot responses
- Maintains workflow state (what data has been collected, what the AI recommends next)
- Controls the conversation flow based on Copilot's structured responses

## What to Build

### Spike Structure (2 parallel PoCs)

Create a `spike/` directory (gitignored or in a branch) with two minimal implementations:

#### PoC A: Direct Line (`spike/direct-line/`)

- Use the **Direct Line REST API** (or `botframework-directlinejs` npm package)
- Implement the three core operations against the existing Copilot Studio agent:
  1. Start conversation (generate Direct Line token, open conversation)
  2. Send a user message and collect bot activities
  3. Send a structured payload (simulating card action data) and collect response
- Test: Can you extract structured JSON from bot responses?
- Test: Does conversation state persist correctly across turns?
- Test: What's the latency overhead vs. the current SDK approach?
- Document: Token management (Direct Line tokens expire after 30 min, must be refreshed)
- Document: Activity schema differences from the Copilot Studio SDK

#### PoC B: Copilot Studio SDK — Extended (`spike/copilot-sdk/`)

- Use the existing `@microsoft/agents-copilotstudio-client` (current approach)
- Extend the current pattern to test orchestrator requirements:
  1. Send a message with injected system context / constraints (prepend metadata to user message)
  2. Parse bot response for structured JSON (check if `activity.value`, `activity.entities`, or text contains parseable JSON)
  3. Maintain multi-turn state and verify the SDK handles conversation continuity
- Test: Can you reliably extract structured data from responses?
- Test: Can you inject workflow context into queries without breaking the agent?
- Test: What are the SDK's limitations for programmatic conversation control?

### Evaluation Criteria Document

Create `spike/EVALUATION.md` comparing both approaches across:

| Criterion | Direct Line | Copilot Studio SDK |
|-----------|-------------|-------------------|
| **Structured output extraction** | Can parse activity.value, channelData, entities | Limited to text + attachments |
| **Conversation control** | Full activity-level control | SDK abstracts internals |
| **Token management** | Manual (30-min DL tokens + refresh) | SDK handles internally |
| **Multi-bot support** | Any Bot Framework bot | Copilot Studio only |
| **Latency** | Measured in PoC | Measured in PoC |
| **Streaming support** | WebSocket or polling | SDK streaming generators |
| **Maintenance burden** | More code, more control | Less code, SDK updates |
| **Azure integration** | Azure Bot Service required | Direct to Copilot Studio |

### Recommendation

The spike must conclude with a clear **GO / NO-GO** recommendation:
- **GO Direct Line** if: structured output extraction is significantly better, multi-bot is needed, or SDK limitations block the orchestrator pattern
- **GO SDK (keep current)** if: SDK handles all orchestrator needs, structured data can be extracted reliably, and the reduced maintenance burden outweighs flexibility

## Constraints

- **Time-boxed: 2-3 phases maximum.** This is a spike, not a full implementation. Each PoC should be ~200 lines of focused test code, not a production-ready integration.
- Do NOT modify the existing `server/src/` code. The spike lives in isolation.
- Both PoCs must use the **same Copilot Studio agent** for a fair comparison.
- Measure actual latency numbers (start conversation, send message, receive response) — don't guess.
- If Direct Line requires an Azure Bot Service resource that doesn't exist yet, document the setup steps but don't block the spike on infrastructure provisioning — test with a mock or existing resource.

## Success Criteria

1. Both PoCs can start a conversation, send a message, and receive a response from the same Copilot Studio agent
2. `EVALUATION.md` has measured latency numbers for both approaches
3. Structured output extraction is tested with a real Copilot response (not mocked)
4. A clear recommendation is documented with rationale
5. The recommendation accounts for the dynamic workflow orchestrator use case (v1.5)
6. Any infrastructure requirements (Azure Bot Service, Direct Line secret, etc.) are documented

## Dependencies

- v1.2 (Authentication) is NOT required — the spike can use stub tokens
- Requires access to the existing Copilot Studio agent (same one used in dev today)
- If testing Direct Line: may need an Azure Bot Service resource with a Direct Line channel configured

## Risks

- Direct Line may require additional Azure infrastructure that takes time to provision
- The Copilot Studio SDK is relatively new — documentation may be incomplete for advanced use cases
- Structured output depends on how the Copilot Studio agent is configured — if the agent doesn't return structured JSON, neither channel will extract it well (this is an agent configuration issue, not a channel issue)
